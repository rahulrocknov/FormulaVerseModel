{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c92b0c",
   "metadata": {},
   "source": [
    "DATASET PREIVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa4a1492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asdiv\n",
      "Dataset({\n",
      "    features: ['body', 'question', 'solution_type', 'answer', 'formula'],\n",
      "    num_rows: 2305\n",
      "})\n",
      "{'body': 'Seven red apples and two green apples are in the basket.', 'question': 'How many apples are in the basket?', 'solution_type': 'Addition', 'answer': '9 (apples)', 'formula': '7+2=9'}\n",
      "{'body': 'Ellen has six more balls than Marin. Marin has nine balls.', 'question': 'How many balls does Ellen have?', 'solution_type': 'Addition', 'answer': '15 (balls)', 'formula': '6+9=15'}\n",
      "{'body': 'Janet has nine oranges and Sharon has seven oranges.', 'question': 'How many oranges do Janet and Sharon have together? ', 'solution_type': 'Addition', 'answer': '16 (oranges)', 'formula': '9+7=16'}\n",
      "{'body': 'Allan brought two balloons and Jake brought four balloons to the park.', 'question': 'How many balloons did Allan and Jake have in the park?', 'solution_type': 'Addition', 'answer': '6 (balloons)', 'formula': '2+4=6'}\n",
      "{'body': 'Adam has five more apples than Jackie. Jackie has nine apples.', 'question': 'How many apples does Adam have?', 'solution_type': 'Addition', 'answer': '14 (apples)', 'formula': '5+9=14'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "asdiv = load_from_disk(\"datasets/data/hf/asdiv_local\")\n",
    "print(\"Asdiv\")\n",
    "print(asdiv)\n",
    "for i in range(5):\n",
    "    print(asdiv[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37fcefc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mathqa\n",
      "Number of samples: 29837\n",
      "First sample keys: dict_keys(['Problem', 'Rationale', 'options', 'correct', 'annotated_formula', 'linear_formula', 'category'])\n",
      "First sample: {'Problem': \"the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\", 'Rationale': '\"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs . 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = rs . 400 answer : option a\"', 'options': 'a ) rs . 400 , b ) rs . 300 , c ) rs . 500 , d ) rs . 350 , e ) none of these', 'correct': 'a', 'annotated_formula': 'divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))', 'linear_formula': 'multiply(n2,const_100)|multiply(n0,n1)|divide(#0,#1)|multiply(#2,const_100)|divide(#3,#1)|', 'category': 'gain'}\n",
      "First sample: {'Problem': 'average age of students of an adult school is 40 years . 120 new students whose average age is 32 years joined the school . as a result the average age is decreased by 4 years . find the number of students of the school after joining of the new students .', 'Rationale': '\"explanation : let the original no . of students be x . according to situation , 40 x + 120 * 32 = ( x + 120 ) 36 ⇒ x = 120 so , required no . of students after joining the new students = x + 120 = 240 . answer : d\"', 'options': 'a ) 1200 , b ) 120 , c ) 360 , d ) 240 , e ) none of these', 'correct': 'd', 'annotated_formula': 'multiply(divide(subtract(multiply(add(32, 4), 120), multiply(120, 32)), subtract(40, add(32, 4))), 4)', 'linear_formula': 'add(n2,n3)|multiply(n1,n2)|multiply(n1,#0)|subtract(n0,#0)|subtract(#2,#1)|divide(#4,#3)|multiply(n3,#5)|', 'category': 'general'}\n",
      "First sample: {'Problem': 'sophia finished 2 / 3 of a book . she calculated that she finished 90 more pages than she has yet to read . how long is her book ?', 'Rationale': 'let xx be the total number of pages in the book , then she finished 23 ⋅ x 23 ⋅ x pages . then she has x − 23 ⋅ x = 13 ⋅ xx − 23 ⋅ x = 13 ⋅ x pages left . 23 ⋅ x − 13 ⋅ x = 9023 ⋅ x − 13 ⋅ x = 90 13 ⋅ x = 9013 ⋅ x = 90 x = 270 x = 270 so the book is 270 pages long . answer : b', 'options': 'a ) 229 , b ) 270 , c ) 877 , d ) 266 , e ) 281', 'correct': 'b', 'annotated_formula': 'divide(90, subtract(const_1, divide(2, 3)))', 'linear_formula': 'divide(n0,n1)|subtract(const_1,#0)|divide(n2,#1)', 'category': 'general'}\n",
      "First sample: {'Problem': '120 is what percent of 50 ?', 'Rationale': '\"50 * x = 120 - - > x = 2.4 - - > 2.4 expressed as percent is 240 % . answer : b .\"', 'options': 'a ) 5 % , b ) 240 % , c ) 50 % , d ) 2 % , e ) 500 %', 'correct': 'b', 'annotated_formula': 'multiply(divide(120, 50), const_100)', 'linear_formula': 'divide(n0,n1)|multiply(#0,const_100)|', 'category': 'gain'}\n",
      "First sample: {'Problem': 'there are 10 girls and 20 boys in a classroom . what is the ratio of girls to boys ?', 'Rationale': 'if girls is 10 and boys is 20 , then 10 / 20 . so ratio of girls to boys is = 10 / 20 = 1 / 2 answer : a', 'options': 'a ) 1 / 2 , b ) 1 / 3 , c ) 1 / 5 , d ) 10 / 30 , e ) 2 / 5', 'correct': 'a', 'annotated_formula': 'divide(10, 20)', 'linear_formula': 'divide(n0,n1)', 'category': 'other'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# train.json\n",
    "with open(\"datasets/data/mathqa/train.json\", \"r\") as f:\n",
    "    mathqa_train = json.load(f)\n",
    "    \n",
    "print(\"mathqa\")\n",
    "print(\"Number of samples:\", len(mathqa_train))\n",
    "print(\"First sample keys:\", mathqa_train[0].keys())\n",
    "for i in range(5):\n",
    "    print(\"First sample:\", mathqa_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bebfc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mwaps\n",
      "Dataset({\n",
      "    features: ['id', 'question', 'chain', 'result', 'result_float', 'equation', 'expression'],\n",
      "    num_rows: 1089\n",
      "})\n",
      "{'id': 'mawps__8kCVLDe7ByufbvB8', 'question': 'Mark had 2 Doll. Roland proffered him some more. Now Mark has 161 Doll. How many did Roland proffer him?', 'chain': '<gadget id=\"calculator\">161 - 2</gadget>\\n<output>159</output>\\n\\n<result>159</result>', 'result': '159', 'result_float': 159.0, 'equation': 'x = 161 - 2', 'expression': '161-2'}\n",
      "{'id': 'mawps__7bhf7hPk6pDUOioA', 'question': 'Gloria had some raspberry. Margaret gave him 7 more. Now Gloria has 33 raspberry. How many raspberry did Gloria have in the first?', 'chain': '<gadget id=\"calculator\">33 - 7</gadget>\\n<output>26</output>\\n\\n<result>26</result>', 'result': '26', 'result_float': 26.0, 'equation': 'x = 33 - 7', 'expression': '33-7'}\n",
      "{'id': 'mawps__8H7IbSn9KDIuz1S3', 'question': 'Tina had 7 raspberry . He hash each raspberry into 10 slices . How many raspberry slices did Tina make?', 'chain': '<gadget id=\"calculator\">10 * 7</gadget>\\n<output>70</output>\\n\\n<result>70</result>', 'result': '70', 'result_float': 70.0, 'equation': 'x = 10 * 7', 'expression': '10*7'}\n",
      "{'id': 'mawps__3KCjxPLB2Y4UshZq', 'question': 'Ernesto had some pear. Jimmie gave him 8 more. Now Ernesto has 35 pear. How many pear did Ernesto have primitively?', 'chain': '<gadget id=\"calculator\">35 - 8</gadget>\\n<output>27</output>\\n\\n<result>27</result>', 'result': '27', 'result_float': 27.0, 'equation': 'x = 35 - 8', 'expression': '35-8'}\n",
      "{'id': 'mawps__SrIKhLXVqMZKEN4x', 'question': 'Elizabeth had some cherry. Don took 74 from him. Now Elizabeth has 74 cherry. How many cherry Elizabeth had in the beginning?', 'chain': '<gadget id=\"calculator\">74 + 74</gadget>\\n<output>148</output>\\n\\n<result>148</result>', 'result': '148', 'result_float': 148.0, 'equation': 'x = 74 + 74', 'expression': '74+74'}\n"
     ]
    }
   ],
   "source": [
    "mawps = load_from_disk(\"datasets/data/mawps_dataset/train\")\n",
    "print(\"mwaps\")\n",
    "print(mawps)\n",
    "for i in range(5):\n",
    "    print(mawps[i])   # preview first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c30070c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths:\n",
      " train: True datasets\\data\\mathqa\\train.json\n",
      " dev:   True datasets\\data\\mathqa\\dev.json\n",
      " test:  True datasets\\data\\mathqa\\test.json\n",
      " const: True datasets\\data\\mathqa\\constant_list.txt\n",
      " ops:   True datasets\\data\\mathqa\\operation_list.txt\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 1: imports & paths\n",
    "import json, re, os\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Adjust if needed ---\n",
    "ROOT = Path(\"datasets/data/mathqa\")\n",
    "TRAIN_PATH = ROOT / \"train.json\"\n",
    "DEV_PATH   = ROOT / \"dev.json\"\n",
    "TEST_PATH  = ROOT / \"test.json\"\n",
    "CONST_PATH = ROOT / \"constant_list.txt\"\n",
    "OP_PATH    = ROOT / \"operation_list.txt\"\n",
    "\n",
    "OUTDIR = ROOT / \"processed\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Paths:\")\n",
    "print(\" train:\", TRAIN_PATH.exists(), TRAIN_PATH)\n",
    "print(\" dev:  \", DEV_PATH.exists(), DEV_PATH)\n",
    "print(\" test: \", TEST_PATH.exists(), TEST_PATH)\n",
    "print(\" const:\", CONST_PATH.exists(), CONST_PATH)\n",
    "print(\" ops:  \", OP_PATH.exists(), OP_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5385cedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded constants: 23\n",
      "First constants: ['CONST_2', 'CONST_1.6', 'CONST_10', 'CONST_180', 'CONST_0.3937', 'CONST_3.6', 'CONST_6', 'CONST_0.25', 'CONST_DEG_TO_RAD', 'CONST_3']\n",
      "Loaded operations: 77\n",
      "First operations: ['subtract', 'max', 'semi_circle_perimiter', 'square_edge_by_perimeter', 'permutation', 'min', 'reminder', 'surface_cylinder', 'trapezium_area', 'triangle_area', 'gain_percent', 'sum_consecutive_number', 'stream_speed', 'volume_rectangular_prism', 'count_interval', 'triangle_area_three_edges', 'cube_edge_by_volume', 'add', 'sqrt', 'p_after_gain']\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 2: load constants & operations\n",
    "def load_lines(path):\n",
    "    if not path.exists():\n",
    "        return []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [ln.strip() for ln in f if ln.strip()]\n",
    "    return lines\n",
    "\n",
    "constants = load_lines(CONST_PATH)\n",
    "operations = load_lines(OP_PATH)\n",
    "\n",
    "# normalize constants and ops\n",
    "constants_set = set([c.strip() for c in constants])\n",
    "ops_set = set([o.strip() for o in operations])\n",
    "\n",
    "print(\"Loaded constants:\", len(constants_set))\n",
    "print(\"First constants:\", list(constants_set)[:10])\n",
    "print(\"Loaded operations:\", len(ops_set))\n",
    "print(\"First operations:\", list(ops_set)[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2794033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook cell 3: helper canonicalization functions\n",
    "# We'll map:\n",
    "#  - n#   -> ARG#\n",
    "#  - const_name  -> CONST_NAME (upper)\n",
    "#  - #k   -> TEMPk\n",
    "token_map_patterns = [\n",
    "    (re.compile(r\"\\bn(\\d+)\\b\"), lambda m: f\"ARG{m.group(1)}\"),\n",
    "    (re.compile(r\"\\bconst_([A-Za-z0-9_.]+)\\b\"), lambda m: f\"CONST_{m.group(1).upper().replace('.','_')}\"),\n",
    "    (re.compile(r\"\\#(\\d+)\"), lambda m: f\"TEMP{m.group(1)}\"),\n",
    "]\n",
    "\n",
    "def canonicalize_linear_formula(linear, validate_ops=True):\n",
    "    \"\"\"\n",
    "    Convert linear_formula tokens into canonical placeholders.\n",
    "    Optionally validate presence of known operations (not required, but useful).\n",
    "    \"\"\"\n",
    "    if not linear:\n",
    "        return \"\"\n",
    "    s = linear.strip().strip('|')\n",
    "    # apply token replacements\n",
    "    for pat, fn in token_map_patterns:\n",
    "        s = pat.sub(fn, s)\n",
    "    # optionally validate operations: linear is pipe-separated tokens like \"add(ARG0,ARG1)|multiply(ARG1,ARG2)\"\n",
    "    if validate_ops:\n",
    "        parts = s.split(\"|\")\n",
    "        cleaned_parts = []\n",
    "        for p in parts:\n",
    "            # extract op name: beginning until '('\n",
    "            op_match = re.match(r\"\\s*([a-zA-Z0-9_]+)\\s*\\(\", p)\n",
    "            if op_match:\n",
    "                op = op_match.group(1)\n",
    "                # allow a few variants: e.g. \"divide\" etc.\n",
    "                if op not in ops_set:\n",
    "                    # if unknown, keep but mark with UNKOP_ prefix\n",
    "                    p = p.replace(op, \"UNKOP_\" + op)\n",
    "            cleaned_parts.append(p)\n",
    "        s = \"|\".join(cleaned_parts)\n",
    "    s = re.sub(r\"\\s*\\|\\s*\", \"|\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def canonicalize_annotated_formula(annot):\n",
    "    \"\"\"\n",
    "    Convert annotated_formula where functions are nested into canonical tokens similarly.\n",
    "    \"\"\"\n",
    "    if not annot:\n",
    "        return \"\"\n",
    "    s = annot\n",
    "    for pat, fn in token_map_patterns:\n",
    "        s = pat.sub(fn, s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fab6b072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts train/dev/test: 29837 4475 2985\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 4: load JSON splits\n",
    "def load_json(path):\n",
    "    if not path.exists():\n",
    "        return []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train = load_json(TRAIN_PATH)\n",
    "dev   = load_json(DEV_PATH)\n",
    "test  = load_json(TEST_PATH)\n",
    "print(\"counts train/dev/test:\", len(train), len(dev), len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d1a6c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed examples: 37297\n",
      "Total unique templates found: 8762\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 5: process splits & build template bank\n",
    "def clean_text(s):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "all_data = []\n",
    "template_counter = Counter()\n",
    "template_examples = defaultdict(list)\n",
    "\n",
    "for split_name, split in [(\"train\", train), (\"dev\", dev), (\"test\", test)]:\n",
    "    for i, item in enumerate(split):\n",
    "        # standard fields (some variants)\n",
    "        problem = clean_text(item.get(\"Problem\") or item.get(\"problem\") or \"\")\n",
    "        rationale = clean_text(item.get(\"Rationale\") or item.get(\"rationale\") or \"\")\n",
    "        linear = item.get(\"linear_formula\")\n",
    "        annotated = item.get(\"annotated_formula\")\n",
    "        # canonicalize\n",
    "        linear_canon = canonicalize_linear_formula(linear)\n",
    "        annot_canon = canonicalize_annotated_formula(annotated)\n",
    "        # prefer linear if available; otherwise annotated\n",
    "        template_key = linear_canon if linear_canon else (annot_canon if annot_canon else \"\")\n",
    "        eid = item.get(\"id\", f\"mathqa_{split_name}_{i}\")\n",
    "        record = {\n",
    "            \"id\": eid,\n",
    "            \"split\": split_name,\n",
    "            \"problem\": problem,\n",
    "            \"rationale\": rationale,\n",
    "            \"linear_formula\": linear_canon,\n",
    "            \"annotated_formula\": annot_canon,\n",
    "            \"raw_linear\": linear,\n",
    "            \"raw_annotated\": annotated,\n",
    "            \"original\": item\n",
    "        }\n",
    "        all_data.append(record)\n",
    "        if template_key:\n",
    "            template_counter[template_key] += 1\n",
    "            # store small example metadata for the template\n",
    "            template_examples[template_key].append({\n",
    "                \"id\": eid,\n",
    "                \"split\": split_name,\n",
    "                \"problem_snippet\": problem[:300]\n",
    "            })\n",
    "\n",
    "print(\"Total processed examples:\", len(all_data))\n",
    "print(\"Total unique templates found:\", len(template_counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8fd2ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset: datasets\\data\\mathqa\\processed\\mathqa_cleaned_all_splits.jsonl\n",
      "Saved template summary CSV: datasets\\data\\mathqa\\processed\\template_bank_summary.csv\n",
      "Saved a JSON of top templates/examples: datasets\\data\\mathqa\\processed\\top_templates_examples.json\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 6: create template bank dataframe & save top templates\n",
    "TOP_N = 500  # adjust how many top templates to keep examples for\n",
    "\n",
    "template_items = [{\"template\": t, \"count\": c, \"examples\": template_examples[t][:5]} \n",
    "                  for t, c in template_counter.most_common()]\n",
    "\n",
    "template_df = pd.DataFrame([{\"template\": ti[\"template\"], \"count\": ti[\"count\"]} for ti in template_items])\n",
    "\n",
    "# Save cleaned dataset (jsonl) and template summaries\n",
    "cleaned_path = OUTDIR / \"mathqa_cleaned_all_splits.jsonl\"\n",
    "with open(cleaned_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for rec in all_data:\n",
    "        # drop \"original\" if too big; we'll keep main fields\n",
    "        out_rec = {\n",
    "            \"id\": rec[\"id\"],\n",
    "            \"split\": rec[\"split\"],\n",
    "            \"problem\": rec[\"problem\"],\n",
    "            \"rationale\": rec[\"rationale\"],\n",
    "            \"linear_formula\": rec[\"linear_formula\"],\n",
    "            \"annotated_formula\": rec[\"annotated_formula\"]\n",
    "        }\n",
    "        fout.write(json.dumps(out_rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "template_csv = OUTDIR / \"template_bank_summary.csv\"\n",
    "template_df.to_csv(template_csv, index=False)\n",
    "\n",
    "top_examples_path = OUTDIR / \"top_templates_examples.json\"\n",
    "top_templates_json = {t: template_examples[t][:10] for t, _ in template_counter.most_common(TOP_N)}\n",
    "with open(top_examples_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    json.dump(top_templates_json, fout, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved cleaned dataset:\", cleaned_path)\n",
    "print(\"Saved template summary CSV:\", template_csv)\n",
    "print(\"Saved a JSON of top templates/examples:\", top_examples_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e1e8ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 templates (template => count):\n",
      "  241  divide(ARG0,ARG1)\n",
      "  239  divide(ARG0,ARG1)|multiply(TEMP0,CONST_100)\n",
      "  175  multiply(ARG0,ARG1)|divide(TEMP0,ARG2)\n",
      "  175  multiply(ARG0,ARG2)\n",
      "  165  add(ARG0,ARG1)|divide(TEMP0,CONST_2)\n",
      "  149  divide(ARG1,ARG0)\n",
      "  138  multiply(ARG0,ARG1)\n",
      "  116  add(ARG0,CONST_1)\n",
      "  110  multiply(ARG1,CONST_0_2778)|divide(ARG0,TEMP0)\n",
      "  106  multiply(ARG0,ARG1)|add(ARG2,TEMP0)\n",
      "  106  multiply(ARG0,CONST_1000)|divide(TEMP0,CONST_3600)|multiply(ARG1,TEMP1)\n",
      "   93  subtract(ARG1,ARG0)|divide(TEMP0,ARG0)|multiply(TEMP1,CONST_100)\n",
      "   86  add(ARG0,ARG1)\n",
      "   82  negate(ARG3)|subtract(ARG1,ARG2)|subtract(ARG0,ARG1)|divide(TEMP1,TEMP2)|multiply(TEMP3,TEMP1)|subtract(TEMP0,TEMP4)\n",
      "   81  add(ARG0,ARG2)|multiply(ARG1,CONST_0_2778)|divide(TEMP0,TEMP1)\n",
      "   77  add(ARG0,ARG1)|add(ARG2,ARG3)|multiply(TEMP1,CONST_0_2778)|divide(TEMP0,TEMP2)\n",
      "   73  subtract(ARG1,ARG2)|multiply(TEMP0,CONST_0_2778)|divide(ARG0,TEMP1)\n",
      "   73  add(ARG1,CONST_4)|factorial(ARG1)|subtract(CONST_4,CONST_1)|factorial(TEMP2)|subtract(TEMP0,CONST_1)|factorial(TEMP4)|multiply(TEMP1,TEMP3)|divide(TEMP5,TEMP6)\n",
      "   73  subtract(ARG0,ARG1)\n",
      "   68  subtract(ARG1,ARG0)\n",
      "\n",
      "Template length distribution (number of pipe-separated ops):\n",
      "count    8762.000000\n",
      "mean        5.066195\n",
      "std         3.051130\n",
      "min         1.000000\n",
      "25%         3.000000\n",
      "50%         4.000000\n",
      "75%         6.000000\n",
      "max        55.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 7: quick inspection - show top 20 templates and some stats\n",
    "print(\"Top 20 templates (template => count):\")\n",
    "for t, c in template_counter.most_common(20):\n",
    "    print(f\"{c:5d}  {t}\")\n",
    "\n",
    "# show distribution of template lengths (simple)\n",
    "lens = [len(t.split(\"|\")) if t else 0 for t in template_counter.keys()]\n",
    "s = pd.Series(lens)\n",
    "print(\"\\nTemplate length distribution (number of pipe-separated ops):\")\n",
    "print(s.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dea484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample top templates with extracted ARG placeholders:\n",
      "  241  args=['ARG0', 'ARG1']  -> divide(ARG0,ARG1)\n",
      "  239  args=['ARG0', 'ARG1']  -> divide(ARG0,ARG1)|multiply(TEMP0,CONST_100)\n",
      "  175  args=['ARG0', 'ARG1', 'ARG2']  -> multiply(ARG0,ARG1)|divide(TEMP0,ARG2)\n",
      "  175  args=['ARG0', 'ARG2']  -> multiply(ARG0,ARG2)\n",
      "  165  args=['ARG0', 'ARG1']  -> add(ARG0,ARG1)|divide(TEMP0,CONST_2)\n",
      "  149  args=['ARG0', 'ARG1']  -> divide(ARG1,ARG0)\n",
      "  138  args=['ARG0', 'ARG1']  -> multiply(ARG0,ARG1)\n",
      "  116  args=['ARG0']  -> add(ARG0,CONST_1)\n",
      "  110  args=['ARG0', 'ARG1']  -> multiply(ARG1,CONST_0_2778)|divide(ARG0,TEMP0)\n",
      "  106  args=['ARG0', 'ARG1', 'ARG2']  -> multiply(ARG0,ARG1)|add(ARG2,TEMP0)\n",
      "  106  args=['ARG0', 'ARG1']  -> multiply(ARG0,CONST_1000)|divide(TEMP0,CONST_3600)|multiply(ARG1,TEMP1)\n",
      "   93  args=['ARG0', 'ARG1']  -> subtract(ARG1,ARG0)|divide(TEMP0,ARG0)|multiply(TEMP1,CONST_100)\n",
      "   86  args=['ARG0', 'ARG1']  -> add(ARG0,ARG1)\n",
      "   82  args=['ARG0', 'ARG1', 'ARG2', 'ARG3']  -> negate(ARG3)|subtract(ARG1,ARG2)|subtract(ARG0,ARG1)|divide(TEMP1,TEMP2)|multiply(TEMP3,TEMP1)|subtract(TEMP0,TEMP4)\n",
      "   81  args=['ARG0', 'ARG1', 'ARG2']  -> add(ARG0,ARG2)|multiply(ARG1,CONST_0_2778)|divide(TEMP0,TEMP1)\n",
      "   77  args=['ARG0', 'ARG1', 'ARG2', 'ARG3']  -> add(ARG0,ARG1)|add(ARG2,ARG3)|multiply(TEMP1,CONST_0_2778)|divide(TEMP0,TEMP2)\n",
      "   73  args=['ARG0', 'ARG1', 'ARG2']  -> subtract(ARG1,ARG2)|multiply(TEMP0,CONST_0_2778)|divide(ARG0,TEMP1)\n",
      "   73  args=['ARG1']  -> add(ARG1,CONST_4)|factorial(ARG1)|subtract(CONST_4,CONST_1)|factorial(TEMP2)|subtract(TEMP0,CONST_1)|factorial(TEMP4)|multiply(TEMP1,TEMP3)|divide(TEMP5,TEMP6)\n",
      "   73  args=['ARG0', 'ARG1']  -> subtract(ARG0,ARG1)\n",
      "   68  args=['ARG0', 'ARG1']  -> subtract(ARG1,ARG0)\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell 8: simple slot extractor (optional)\n",
    "# This will show how many unique ARG# placeholders exist in top templates and their counts.\n",
    "def extract_args(template):\n",
    "    return sorted(set(re.findall(r\"ARG\\d+\", template)))\n",
    "\n",
    "top_k = 50\n",
    "print(\"\\nSample top templates with extracted ARG placeholders:\")\n",
    "for t, c in template_counter.most_common(top_k)[:20]:\n",
    "    print(f\"{c:5d}  args={extract_args(t)}  -> {t}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54de7231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: True datasets\\data\\mathqa\\processed\\mathqa_cleaned_all_splits.jsonl\n",
      "Outdir: FinalData\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: imports & paths\n",
    "from pathlib import Path\n",
    "import json, re, hashlib\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path(\"datasets/data/mathqa\")\n",
    "INPATH = ROOT / \"processed\" / \"mathqa_cleaned_all_splits.jsonl\"\n",
    "OUTDIR = Path(\"FinalData\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Input:\", INPATH.exists(), INPATH)\n",
    "print(\"Outdir:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d60fe9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: small parser for annotated_formula -> AST\n",
    "# annotated_formula example: \"divide(90, subtract(const_1, divide(2, 3)))\"\n",
    "# Parser returns nested dicts: {\"op\":\"divide\",\"args\":[...]} or leaf strings like \"ARG0\" or \"CONST_100\" or \"90\"\n",
    "\n",
    "_tok_re = re.compile(r\"\\s*([A-Za-z0-9_.#]+)\\s*(\\(|,|\\))?\")\n",
    "\n",
    "def parse_annotated_formula(s):\n",
    "    \"\"\"\n",
    "    Recursive simple parser for function-call style annotated_formula.\n",
    "    Returns AST nodes:\n",
    "      - dict: {\"op\": op_name, \"args\": [arg1,...]}\n",
    "      - leaf str: token like ARG0, CONST_100 or numeric literal\n",
    "    \"\"\"\n",
    "    if not s or not isinstance(s, str):\n",
    "        return None\n",
    "    # remove surrounding whitespace\n",
    "    s = s.strip()\n",
    "    # inner recursive parser using index\n",
    "    idx = 0\n",
    "    n = len(s)\n",
    "\n",
    "    def parse_expr(i):\n",
    "        # parse token (op or literal)\n",
    "        # token can be letters/numbers/._# then optionally '(' args ')'\n",
    "        m = _tok_re.match(s, i)\n",
    "        if not m:\n",
    "            raise ValueError(f\"Parse error at pos {i} in {s!r}\")\n",
    "        token = m.group(1)\n",
    "        sep = m.group(2)\n",
    "        j = m.end()\n",
    "        if sep == \"(\":\n",
    "            # parse args until matching ')'\n",
    "            args = []\n",
    "            # handle empty arg lists (rare)\n",
    "            while True:\n",
    "                # peek for closing parenthesis\n",
    "                # skip whitespace\n",
    "                while j < n and s[j].isspace():\n",
    "                    j += 1\n",
    "                if j < n and s[j] == \")\":\n",
    "                    j += 1\n",
    "                    break\n",
    "                # parse next arg\n",
    "                arg_node, j = parse_expr(j)\n",
    "                args.append(arg_node)\n",
    "                # skip spaces\n",
    "                while j < n and s[j].isspace():\n",
    "                    j += 1\n",
    "                # next char should be ',' or ')'\n",
    "                if j < n and s[j] == \",\":\n",
    "                    j += 1\n",
    "                    continue\n",
    "                if j < n and s[j] == \")\":\n",
    "                    j += 1\n",
    "                    break\n",
    "                # otherwise continue (watch for end)\n",
    "            return ({\"op\": token, \"args\": args}, j)\n",
    "        else:\n",
    "            # leaf token (could be numeric or const or ARG# or #temp)\n",
    "            return (token, j)\n",
    "\n",
    "    node, pos = parse_expr(0)\n",
    "    # ensure consumed\n",
    "    # pos may be less than n if trailing pipes exist (shouldn't for annotated)\n",
    "    return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff8ac600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: AST -> canonical template & AST serializer\n",
    "def ast_to_template(node):\n",
    "    \"\"\"\n",
    "    Convert AST node into canonical template string where ARG\\d+ -> {ARG#}, const_* -> CONST_*, temps preserved.\n",
    "    Returns serialized string (node-based) used as template key.\n",
    "    \"\"\"\n",
    "    if node is None:\n",
    "        return \"\"\n",
    "    if isinstance(node, str):\n",
    "        # map tokens\n",
    "        tok = node.strip()\n",
    "        # standardize ARGn -> {ARGn}, const_x -> CONST_X\n",
    "        m = re.match(r\"n(\\d+)$\", tok)  # sometimes n0 style (rare in annotated)\n",
    "        if m:\n",
    "            return \"{\" + \"ARG\" + m.group(1) + \"}\"\n",
    "        m2 = re.match(r\"ARG(\\d+)$\", tok)\n",
    "        if m2:\n",
    "            return \"{\" + \"ARG\" + m2.group(1) + \"}\"\n",
    "        m3 = re.match(r\"const_([A-Za-z0-9_.]+)$\", tok, flags=re.I)\n",
    "        if m3:\n",
    "            return \"CONST_\" + m3.group(1).upper().replace(\".\", \"_\")\n",
    "        # temp like #0 or TEMP0\n",
    "        m4 = re.match(r\"#(\\d+)$\", tok)\n",
    "        if m4:\n",
    "            return \"TEMP\" + m4.group(1)\n",
    "        # else numeric literal or other token -> keep as-is\n",
    "        return tok\n",
    "    # dict node\n",
    "    op = node.get(\"op\")\n",
    "    args = node.get(\"args\", [])\n",
    "    arg_strs = [ast_to_template(a) for a in args]\n",
    "    return f\"{op}(\" + \",\".join(arg_strs) + \")\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd743882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: AST -> infix conversion (best-effort)\n",
    "_infix_map = {\n",
    "    \"add\": (\"{a} + {b}\", 2),\n",
    "    \"subtract\": (\"{a} - {b}\", 2),\n",
    "    \"multiply\": (\"{a} * {b}\", 2),\n",
    "    \"divide\": (\"{a} / {b}\", 2),\n",
    "    \"power\": (\"({a}) ** ({b})\", 2),\n",
    "    \"negate\": (\"-({a})\", 1),\n",
    "    \"sqrt\": (\"sqrt({a})\", 1),\n",
    "    \"log\": (\"log({a})\", 1),\n",
    "    \"max\": (\"max({a},{b})\", 2),\n",
    "    \"min\": (\"min({a},{b})\", 2),\n",
    "    # if more operations required, extend here\n",
    "}\n",
    "\n",
    "def ast_to_infix(node):\n",
    "    if node is None:\n",
    "        return \"\"\n",
    "    if isinstance(node, str):\n",
    "        return node\n",
    "    op = node.get(\"op\")\n",
    "    args = node.get(\"args\", [])\n",
    "    infix_args = [ast_to_infix(a) for a in args]\n",
    "    if op in _infix_map:\n",
    "        pattern, arity = _infix_map[op]\n",
    "        if arity == 1 and len(infix_args) >= 1:\n",
    "            return pattern.format(a=infix_args[0])\n",
    "        if arity == 2 and len(infix_args) >= 2:\n",
    "            return pattern.format(a=infix_args[0], b=infix_args[1])\n",
    "    # default: function style\n",
    "    return f\"{op}(\" + \",\".join(infix_args) + \")\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5b2a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: utilities to extract numeric tokens from problem text\n",
    "_num_re = re.compile(r'(?:(?:\\d+(?:\\.\\d+)?)|(?:\\d+\\s*/\\s*\\d+)|(?:\\d+\\.\\d+))')\n",
    "\n",
    "def extract_numbers_from_text(text):\n",
    "    text = text or \"\"\n",
    "    # return list of strings and parsed floats where possible\n",
    "    nums = []\n",
    "    for m in _num_re.finditer(text):\n",
    "        raw = m.group(0)\n",
    "        raw = raw.replace(\" \", \"\")\n",
    "        # handle fraction\n",
    "        if \"/\" in raw:\n",
    "            try:\n",
    "                a,b = raw.split(\"/\")\n",
    "                val = float(a)/float(b)\n",
    "            except Exception:\n",
    "                val = None\n",
    "        else:\n",
    "            try:\n",
    "                val = float(raw)\n",
    "            except:\n",
    "                val = None\n",
    "        nums.append({\"text\": raw, \"value\": val, \"span\": m.span()})\n",
    "    return nums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d207a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: main loop - read file, parse AST, build template bank & semantic specs\n",
    "template_index = {}   # template_str -> template_id (hash)\n",
    "template_data = {}    # template_id -> info\n",
    "template_examples = defaultdict(list)\n",
    "semantic_specs = []   # list of per-example semantic JSON\n",
    "\n",
    "with open(INPATH, \"r\", encoding=\"utf-8\") as fin:\n",
    "    for line in fin:\n",
    "        item = json.loads(line)\n",
    "        eid = item.get(\"id\")\n",
    "        problem = item.get(\"problem\", \"\")\n",
    "        linear = item.get(\"linear_formula\", \"\") or \"\"\n",
    "        annotated = item.get(\"annotated_formula\", \"\") or \"\"\n",
    "        # prefer annotated_formula for AST parsing (linear is flattened)\n",
    "        source_formula = annotated if annotated else linear\n",
    "        try:\n",
    "            ast = parse_annotated_formula(source_formula) if source_formula else None\n",
    "        except Exception as e:\n",
    "            ast = None\n",
    "        template_str = ast_to_template(ast) if ast else (\"LINEAR:\" + linear if linear else \"\")\n",
    "        # template id: hash shorter\n",
    "        tid = hashlib.sha1(template_str.encode(\"utf-8\")).hexdigest()[:12]\n",
    "        if tid not in template_data:\n",
    "            # initialize\n",
    "            template_data[tid] = {\n",
    "                \"template_id\": tid,\n",
    "                \"template_str\": template_str,\n",
    "                \"ast_template\": ast,   # best-effort; serializable?\n",
    "                \"count\": 0,\n",
    "                \"ops\": [],\n",
    "                \"constants\": set(),\n",
    "                \"examples\": []\n",
    "            }\n",
    "        # increment\n",
    "        template_data[tid][\"count\"] += 1\n",
    "        template_data[tid][\"examples\"].append(eid)\n",
    "        # collect ops and constants: traverse AST\n",
    "        ops = set()\n",
    "        consts = set()\n",
    "        argslots = set()\n",
    "        def walk(n):\n",
    "            if n is None:\n",
    "                return\n",
    "            if isinstance(n, str):\n",
    "                tok = n\n",
    "                # identify ARG, CONST, TEMP\n",
    "                if re.match(r\"ARG\\d+\", tok):\n",
    "                    argslots.add(tok)\n",
    "                if re.match(r\"CONST_[A-Z0-9_\\.]+\", tok) or tok.lower().startswith(\"const_\"):\n",
    "                    consts.add(tok)\n",
    "                return\n",
    "            # dict\n",
    "            opn = n.get(\"op\")\n",
    "            if opn:\n",
    "                ops.add(opn)\n",
    "            for a in n.get(\"args\", []):\n",
    "                walk(a)\n",
    "        walk(ast)\n",
    "        template_data[tid][\"ops\"] = sorted(list(ops))\n",
    "        template_data[tid][\"constants\"] = sorted(list(consts))\n",
    "        # prepare semantic spec for this example\n",
    "        infix = ast_to_infix(ast) if ast else \"\"\n",
    "        numbers_in_text = extract_numbers_from_text(problem)\n",
    "        # simple mapping: ARG0->first number, ARG1->second...\n",
    "        arg_to_number = {}\n",
    "        # find all ARG tokens in AST and sort by arg index\n",
    "        arg_tokens = sorted(set(re.findall(r\"ARG(\\d+)\", template_str)), key=lambda x: int(x))\n",
    "        for idx, arg_idx in enumerate(arg_tokens):\n",
    "            key = \"ARG\" + arg_idx\n",
    "            if idx < len(numbers_in_text):\n",
    "                arg_to_number[key] = numbers_in_text[idx][\"text\"]\n",
    "            else:\n",
    "                arg_to_number[key] = None\n",
    "        spec = {\n",
    "            \"id\": eid,\n",
    "            \"template_id\": tid,\n",
    "            \"template_str\": template_str,\n",
    "            \"infix\": infix,\n",
    "            \"ops\": sorted(list(ops)),\n",
    "            \"constants\": sorted(list(consts)),\n",
    "            \"arg_slots\": arg_tokens,\n",
    "            \"arg_to_number_heuristic\": arg_to_number,\n",
    "            \"problem_snippet\": problem[:300]\n",
    "        }\n",
    "        semantic_specs.append(spec)\n",
    "\n",
    "# finalize template list\n",
    "template_list = list(template_data.values())\n",
    "# convert sets to lists for JSON serialization\n",
    "for t in template_list:\n",
    "    if isinstance(t.get(\"constants\"), set):\n",
    "        t[\"constants\"] = sorted(list(t[\"constants\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "147cfc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: FinalData\\template_bank.json\n",
      "Wrote: FinalData\\template_bank_summary.csv\n",
      "Wrote: FinalData\\semantic_specs.jsonl\n",
      "Template count: 8762\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: save outputs (template_bank.json, template_bank_summary.csv, semantic_specs.jsonl)\n",
    "tpl_json_path = OUTDIR / \"template_bank.json\"\n",
    "tpl_csv_path  = OUTDIR / \"template_bank_summary.csv\"\n",
    "specs_path    = OUTDIR / \"semantic_specs.jsonl\"\n",
    "\n",
    "# Write template_bank.json (full)\n",
    "with open(tpl_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(template_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Summary CSV\n",
    "df_rows = []\n",
    "for t in template_list:\n",
    "    df_rows.append({\n",
    "        \"template_id\": t[\"template_id\"],\n",
    "        \"template_str\": t[\"template_str\"],\n",
    "        \"count\": t[\"count\"],\n",
    "        \"ops\": \";\".join(t.get(\"ops\", [])),\n",
    "        \"num_examples\": len(t.get(\"examples\", [])),\n",
    "        \"constants\": \";\".join(t.get(\"constants\", [])),\n",
    "        \"sample_example\": t.get(\"examples\", [None])[0]\n",
    "    })\n",
    "pd.DataFrame(df_rows).sort_values(\"count\", ascending=False).to_csv(tpl_csv_path, index=False)\n",
    "\n",
    "# semantic specs\n",
    "with open(specs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for s in semantic_specs:\n",
    "        f.write(json.dumps(s, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Wrote:\", tpl_json_path)\n",
    "print(\"Wrote:\", tpl_csv_path)\n",
    "print(\"Wrote:\", specs_path)\n",
    "print(\"Template count:\", len(template_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b3f6092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 templates by count:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>template_id</th>\n",
       "      <th>template_str</th>\n",
       "      <th>count</th>\n",
       "      <th>ops</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>constants</th>\n",
       "      <th>sample_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c5df09e2ebc6</td>\n",
       "      <td>LINEAR:divide(ARG0,ARG1)</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d3e7fcc76529</td>\n",
       "      <td>LINEAR:divide(ARG0,ARG1)|multiply(TEMP0,CONST_...</td>\n",
       "      <td>239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b1e389c2c80</td>\n",
       "      <td>LINEAR:multiply(ARG0,ARG2)</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a0abfe4e3a5e</td>\n",
       "      <td>LINEAR:multiply(ARG0,ARG1)|divide(TEMP0,ARG2)</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ba792035ceaa</td>\n",
       "      <td>LINEAR:add(ARG0,ARG1)|divide(TEMP0,CONST_2)</td>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1379ef00d64f</td>\n",
       "      <td>LINEAR:divide(ARG1,ARG0)</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39075bf05f53</td>\n",
       "      <td>LINEAR:multiply(ARG0,ARG1)</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83a080372c1d</td>\n",
       "      <td>LINEAR:add(ARG0,CONST_1)</td>\n",
       "      <td>116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>024224bbcc9b</td>\n",
       "      <td>LINEAR:multiply(ARG1,CONST_0_2778)|divide(ARG0...</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59ad42bbd54f</td>\n",
       "      <td>LINEAR:multiply(ARG0,ARG1)|add(ARG2,TEMP0)</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cb147a48bf44</td>\n",
       "      <td>LINEAR:multiply(ARG0,CONST_1000)|divide(TEMP0,...</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b32ac632dc57</td>\n",
       "      <td>LINEAR:subtract(ARG1,ARG0)|divide(TEMP0,ARG0)|...</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c854b7dab16c</td>\n",
       "      <td>LINEAR:add(ARG0,ARG1)</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99b7ac55523a</td>\n",
       "      <td>LINEAR:negate(ARG3)|subtract(ARG1,ARG2)|subtra...</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>e0a390e49802</td>\n",
       "      <td>LINEAR:add(ARG0,ARG2)|multiply(ARG1,CONST_0_27...</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0e0b55812278</td>\n",
       "      <td>LINEAR:add(ARG0,ARG1)|add(ARG2,ARG3)|multiply(...</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3b3bdccadcb2</td>\n",
       "      <td>LINEAR:subtract(ARG0,ARG1)</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2b317720126e</td>\n",
       "      <td>LINEAR:subtract(ARG1,ARG2)|multiply(TEMP0,CONS...</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>eaef84285bbc</td>\n",
       "      <td>LINEAR:add(ARG1,CONST_4)|factorial(ARG1)|subtr...</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5c9f77fa91f1</td>\n",
       "      <td>LINEAR:subtract(ARG2,ARG1)|divide(TEMP0,ARG0)|...</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mathqa_train_531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     template_id                                       template_str  count  \\\n",
       "0   c5df09e2ebc6                           LINEAR:divide(ARG0,ARG1)    241   \n",
       "1   d3e7fcc76529  LINEAR:divide(ARG0,ARG1)|multiply(TEMP0,CONST_...    239   \n",
       "2   6b1e389c2c80                         LINEAR:multiply(ARG0,ARG2)    175   \n",
       "3   a0abfe4e3a5e      LINEAR:multiply(ARG0,ARG1)|divide(TEMP0,ARG2)    175   \n",
       "4   ba792035ceaa        LINEAR:add(ARG0,ARG1)|divide(TEMP0,CONST_2)    165   \n",
       "5   1379ef00d64f                           LINEAR:divide(ARG1,ARG0)    149   \n",
       "6   39075bf05f53                         LINEAR:multiply(ARG0,ARG1)    138   \n",
       "7   83a080372c1d                           LINEAR:add(ARG0,CONST_1)    116   \n",
       "8   024224bbcc9b  LINEAR:multiply(ARG1,CONST_0_2778)|divide(ARG0...    110   \n",
       "9   59ad42bbd54f         LINEAR:multiply(ARG0,ARG1)|add(ARG2,TEMP0)    106   \n",
       "10  cb147a48bf44  LINEAR:multiply(ARG0,CONST_1000)|divide(TEMP0,...    106   \n",
       "11  b32ac632dc57  LINEAR:subtract(ARG1,ARG0)|divide(TEMP0,ARG0)|...     93   \n",
       "12  c854b7dab16c                              LINEAR:add(ARG0,ARG1)     86   \n",
       "13  99b7ac55523a  LINEAR:negate(ARG3)|subtract(ARG1,ARG2)|subtra...     82   \n",
       "14  e0a390e49802  LINEAR:add(ARG0,ARG2)|multiply(ARG1,CONST_0_27...     81   \n",
       "15  0e0b55812278  LINEAR:add(ARG0,ARG1)|add(ARG2,ARG3)|multiply(...     77   \n",
       "16  3b3bdccadcb2                         LINEAR:subtract(ARG0,ARG1)     73   \n",
       "17  2b317720126e  LINEAR:subtract(ARG1,ARG2)|multiply(TEMP0,CONS...     73   \n",
       "18  eaef84285bbc  LINEAR:add(ARG1,CONST_4)|factorial(ARG1)|subtr...     73   \n",
       "19  5c9f77fa91f1  LINEAR:subtract(ARG2,ARG1)|divide(TEMP0,ARG0)|...     68   \n",
       "\n",
       "    ops  num_examples  constants     sample_example  \n",
       "0   NaN           241        NaN     mathqa_train_4  \n",
       "1   NaN           239        NaN     mathqa_train_3  \n",
       "2   NaN           175        NaN   mathqa_train_282  \n",
       "3   NaN           175        NaN   mathqa_train_220  \n",
       "4   NaN           165        NaN    mathqa_train_23  \n",
       "5   NaN           149        NaN    mathqa_train_52  \n",
       "6   NaN           138        NaN    mathqa_train_37  \n",
       "7   NaN           116        NaN   mathqa_train_552  \n",
       "8   NaN           110        NaN   mathqa_train_261  \n",
       "9   NaN           106        NaN    mathqa_train_10  \n",
       "10  NaN           106        NaN   mathqa_train_458  \n",
       "11  NaN            93        NaN  mathqa_train_1240  \n",
       "12  NaN            86        NaN  mathqa_train_1862  \n",
       "13  NaN            82        NaN   mathqa_train_538  \n",
       "14  NaN            81        NaN   mathqa_train_561  \n",
       "15  NaN            77        NaN    mathqa_train_73  \n",
       "16  NaN            73        NaN   mathqa_train_763  \n",
       "17  NaN            73        NaN    mathqa_train_28  \n",
       "18  NaN            73        NaN   mathqa_train_397  \n",
       "19  NaN            68        NaN   mathqa_train_531  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 8: quick inspection - top templates\n",
    "df = pd.read_csv(OUTDIR / \"template_bank_summary.csv\")\n",
    "print(\"Top 20 templates by count:\")\n",
    "display(df.sort_values(\"count\", ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e50ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"limitations\": [\n",
      "    \"annotated_formula parser is a simple function-call parser and will fail on malformed inputs.\",\n",
      "    \"ARG -> numeric mapping is heuristic: assigns ARG0 -> first numeric token in problem text. This is often correct but not always.\",\n",
      "    \"infix conversion covers common binary ops (add/sub/mult/div/power). Other domain-specific ops remain as func(...) strings.\",\n",
      "    \"we do not yet reliably infer 'solve_for' variable or a formal problem 'type' (quadratic, linear eqn, geometry, etc.).\"\n",
      "  ],\n",
      "  \"next_steps\": [\n",
      "    \"Review top templates and correct/unify templates that differ only by constant token styles.\",\n",
      "    \"Improve ARG mapping using 'linear_formula' when available (it gives ordering of arguments) \\u2014 we can parse linear_formula to get explicit ARG->n mapping.\",\n",
      "    \"Add rules to infer problem type by pattern-matching ops (e.g., contains 'power' and 'add' -> polynomial; contains 'circle_area' -> geometry/circle).\",\n",
      "    \"Create a small human-validated mapping for top ~200 templates to assign semantic role names for slots (e.g., ARG0 -> QUANTITY_A, ARG1 -> RATE).\",\n",
      "    \"Add extraction of numeric units (e.g., 'm', 'kg') using simple heuristics from the problem text and attach to arg slots.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: limitations & next automated improvements (run or do manually)\n",
    "notes = {\n",
    "    \"limitations\": [\n",
    "        \"annotated_formula parser is a simple function-call parser and will fail on malformed inputs.\",\n",
    "        \"ARG -> numeric mapping is heuristic: assigns ARG0 -> first numeric token in problem text. This is often correct but not always.\",\n",
    "        \"infix conversion covers common binary ops (add/sub/mult/div/power). Other domain-specific ops remain as func(...) strings.\",\n",
    "        \"we do not yet reliably infer 'solve_for' variable or a formal problem 'type' (quadratic, linear eqn, geometry, etc.).\"\n",
    "    ],\n",
    "    \"next_steps\": [\n",
    "        \"Review top templates and correct/unify templates that differ only by constant token styles.\",\n",
    "        \"Improve ARG mapping using 'linear_formula' when available (it gives ordering of arguments) — we can parse linear_formula to get explicit ARG->n mapping.\",\n",
    "        \"Add rules to infer problem type by pattern-matching ops (e.g., contains 'power' and 'add' -> polynomial; contains 'circle_area' -> geometry/circle).\",\n",
    "        \"Create a small human-validated mapping for top ~200 templates to assign semantic role names for slots (e.g., ARG0 -> QUANTITY_A, ARG1 -> RATE).\",\n",
    "        \"Add extraction of numeric units (e.g., 'm', 'kg') using simple heuristics from the problem text and attach to arg slots.\"\n",
    "    ]\n",
    "}\n",
    "print(json.dumps(notes, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61f7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
